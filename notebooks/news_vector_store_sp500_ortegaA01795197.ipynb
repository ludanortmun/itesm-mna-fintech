{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "4e231d13",
      "metadata": {
        "id": "4e231d13"
      },
      "source": [
        "# Introduction to vector databases on S&P 500 news"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "35b70aaa",
      "metadata": {
        "id": "35b70aaa"
      },
      "source": [
        " # 📌 Objectives\n",
        "\n",
        " By the end of this notebook, students will be able to:\n",
        "\n",
        " 1. **Load and Explore Financial News Data:**\n",
        "    - Load a preprocessed dataset of financial news headlines and summaries related to S&P 500 companies.\n",
        "    - Inspect and structure relevant metadata including publication date, ticker, and provider.\n",
        "\n",
        " 2. **Build a Custom Vector Store:**\n",
        "    - Combine title and summary text for embedding.\n",
        "    - Implement a vector store from scratch with support for semantic search and optional metadata-based filtering using cosine similarity.\n",
        "\n",
        " 3. **Generate and Use Sentence Embeddings:**\n",
        "    - Apply a pre-trained transformer model (all-MiniLM-L6-v2) to encode text into embeddings for semantic analysis.\n",
        "\n",
        " 4. **Perform Semantic Search with Filtering:**\n",
        "    - Retrieve the most relevant news documents for a given query using both full-dataset and metadata-filtered searches.\n",
        "\n",
        " 5. **Analyze Semantic Search Results:**\n",
        "    - Interpret and visualize results of search queries (e.g., \"AI announcement\").\n",
        "    - Identify temporal patterns and ticker frequency among top-ranked results.\n",
        "\n",
        " 6. **Implement a FAISS-Based Vector Store:**\n",
        "    - Normalize embeddings and use FAISS (IndexFlatIP) to enable efficient similarity search at scale.\n",
        "    - Compare FAISS-based search results with custom vector store results.\n",
        "\n",
        " 7. **Critically Compare Search Systems:**\n",
        "    - Evaluate differences in similarity computation, speed, and scalability between custom and FAISS-based systems.\n",
        "    - Reflect on design trade-offs for real-world vector search systems."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c1034130",
      "metadata": {
        "id": "c1034130"
      },
      "source": [
        "## Install and Import important libraries"
      ]
    },
    {
      "cell_type": "code",
      "id": "a979a47f",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-08-04T06:18:54.274858Z",
          "start_time": "2025-08-04T06:18:54.268415Z"
        },
        "id": "a979a47f"
      },
      "source": [
        "# %pip install sentence-transformers\n",
        "# %pip install faiss-cpu"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "id": "6b9f8680",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-08-04T06:19:05.976514Z",
          "start_time": "2025-08-04T06:18:54.292470Z"
        },
        "id": "6b9f8680"
      },
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "import faiss\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from collections import Counter\n",
        "import matplotlib.pyplot as plt\n",
        "import faiss\n",
        "import yfinance as yf"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "id": "9850dbaa",
      "metadata": {
        "id": "9850dbaa"
      },
      "source": [
        "## Load news data\n",
        "\n",
        "Load the provided news dataset and inspect the contents.\n",
        "\n",
        " 👉 **Instructions**:\n",
        " - Load the CSV file named df_news.csv into a pandas DataFrame.\n",
        " - Convert the PUBLICATION_DATE column to a proper date format (not datetime).\n",
        " - Display the first few rows to understand the data structure. The key columns you’ll be using are:\n",
        "   - TITLE\n",
        "   - SUMMARY\n",
        "   - TICKER\n",
        "   - PROVIDER\n",
        "   - PUBLICATION_DATE\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "2e00999d",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-08-04T06:19:07.202534Z",
          "start_time": "2025-08-04T06:19:07.126765Z"
        },
        "id": "2e00999d"
      },
      "source": [
        "df_news = pd.read_csv('./data/df_news.csv')\n",
        "df_news['PUBLICATION_DATE'] = pd.to_datetime(df_news['PUBLICATION_DATE']).dt.date\n",
        "display(df_news)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "id": "a29da208",
      "metadata": {
        "id": "a29da208"
      },
      "source": [
        "## Implement custom vector store\n",
        "\n",
        "You will now implement a basic vector store from scratch. This class will allow you to:\n",
        "1. Store embedded text and metadata.\n",
        "2. Perform filtered semantic search using cosine similarity.\n",
        "\n",
        " 👉 **Instructions**:\n",
        "\n",
        "### Step 1: Prepare Documents\n",
        " - Combine the TITLE and SUMMARY columns into a single column named EMBEDDED_TEXT.\n",
        " - This combined text will be embedded later.\n",
        "\n",
        "### Step 2: Load Embedding Model\n",
        " - Load the 'all-MiniLM-L6-v2' model from sentence-transformers.\n",
        "\n",
        "### Step 3: Define CustomVectorStore Class\n",
        " Implement the class with the following methods (functions):\n",
        "\n",
        " - '__init__': Accepts an embedding model, list of documents, and corresponding metadata. Computes and stores embeddings for all documents.\n",
        " - search: Takes a query and returns the top k most similar documents, optionally filtered using metadata.\n",
        "   - If a metadata_filter function is provided, apply it before computing similarity.\n",
        "   - Use cosine similarity to compute distances.\n",
        "   - Return the top k results as tuples of: (document, metadata, similarity score).\n",
        "\n",
        " ✅ **Requirements**:\n",
        " - Ensure the number of documents matches the number of metadata entries.\n",
        " - Make use of sklearn.metrics.pairwise.cosine_similarity.\n",
        "\n",
        "You will test your class at the end."
      ]
    },
    {
      "cell_type": "code",
      "id": "24f6c6e7",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-08-04T06:19:07.297505Z",
          "start_time": "2025-08-04T06:19:07.273553Z"
        },
        "id": "24f6c6e7"
      },
      "source": [
        "# Create the EMBEDDED_TEXT column\n",
        "\n",
        "df_news['EMBEDDED_TEXT'] = df_news['TITLE'] + ' ' + df_news['SUMMARY']\n",
        "\n",
        "display(df_news.head())"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-08-04T06:19:21.944450Z",
          "start_time": "2025-08-04T06:19:07.799307Z"
        },
        "id": "266ea9de1244b185"
      },
      "cell_type": "code",
      "source": [
        "# Load the embedding model\n",
        "\n",
        "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')"
      ],
      "id": "266ea9de1244b185",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "id": "afbe52a5",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-08-04T06:21:52.135785Z",
          "start_time": "2025-08-04T06:21:52.115220Z"
        },
        "id": "afbe52a5"
      },
      "source": [
        "class CustomVectorStore:\n",
        "    def __init__(self,\n",
        "                 embedding_model: SentenceTransformer,\n",
        "                 documents: list[str],\n",
        "                 metadata: list[dict[str, str]]):\n",
        "        self.embedding_model = embedding_model\n",
        "        self.documents = documents\n",
        "        self.metadata = metadata\n",
        "\n",
        "        if len(documents) != len(metadata):\n",
        "            raise ValueError(\"Number of documents must match number of metadata entries.\")\n",
        "\n",
        "        self.embeddings = self.embedding_model.encode(documents)\n",
        "\n",
        "    def search(self,\n",
        "               query: str,\n",
        "               k: int = 5,\n",
        "               metadata_filter: dict[str, str] = None):\n",
        "\n",
        "        mask = self._filter_to_mask(metadata_filter)\n",
        "\n",
        "        similarities = cosine_similarity(\n",
        "            self.embedding_model.encode([query]),\n",
        "            np.array([x for x in self._masked(self.embeddings, mask)])\n",
        "        )[0]\n",
        "\n",
        "        result = (\n",
        "            (d, m, s) for d, m, s in zip(\n",
        "                self._masked(self.documents, mask),\n",
        "                self._masked(self.metadata, mask),\n",
        "                similarities\n",
        "            )\n",
        "        )\n",
        "\n",
        "        # Sort by similarity (third item) desc, return top k results\n",
        "        return sorted(result, key = lambda x: x[2], reverse=True)[:k]\n",
        "\n",
        "    def _filter_to_mask(self, metadata_filter):\n",
        "        if metadata_filter is None:\n",
        "            return [True for _ in self.metadata]\n",
        "\n",
        "        return [\n",
        "            self._is_metadata_match(self.metadata[i], metadata_filter) for i in range(len(self.metadata))\n",
        "        ]\n",
        "\n",
        "    @staticmethod\n",
        "    def _is_metadata_match(document_metadata, metadata_filter):\n",
        "        for key, value in metadata_filter.items():\n",
        "            if key not in document_metadata or document_metadata[key] != value:\n",
        "                return False\n",
        "        return True\n",
        "\n",
        "    @staticmethod\n",
        "    def _masked(items, mask):\n",
        "        return (item for i, item in enumerate(items) if mask[i])\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "8832a15b97522d90"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Create and populate the vector store\n",
        "\n",
        " 👉 **Instructions**:\n",
        " - Convert the combined EMBEDDED_TEXT column into a list of strings.\n",
        " - Create a metadata list of dictionaries for each document with keys:\n",
        "   - 'PUBLICATION_DATE'\n",
        "   - 'TICKER'\n",
        "   - 'PROVIDER'\n",
        " - Instantiate your CustomVectorStore using:\n",
        "   - The embedding model.\n",
        "   - The list of document strings.\n",
        "   - The metadata list.\n",
        "\n",
        " After initializing the store, you should be able to perform searches using:\n",
        "'store.search(\"Apple earnings\", k=3)'\n"
      ],
      "id": "8832a15b97522d90"
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-08-04T06:19:22.071619Z",
          "start_time": "2025-08-04T06:19:22.055698Z"
        },
        "id": "c0d7cb4e768fbb9"
      },
      "cell_type": "code",
      "source": [
        "documents = df_news['EMBEDDED_TEXT'].tolist()\n",
        "\n",
        "display(documents[:5])  # Display first 5 documents to verify"
      ],
      "id": "c0d7cb4e768fbb9",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "id": "ced30e19",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-08-04T06:19:22.152042Z",
          "start_time": "2025-08-04T06:19:22.135926Z"
        },
        "id": "ced30e19"
      },
      "source": [
        "metadata = []\n",
        "\n",
        "for row in df_news.itertuples():\n",
        "    metadata.append({\n",
        "        'PUBLICATION_DATE': row.PUBLICATION_DATE,\n",
        "        'TICKER': row.TICKER,\n",
        "        'PROVIDER': row.PROVIDER\n",
        "    })\n",
        "\n",
        "display(metadata[:5])  # Display first 5 metadata entries to verify"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-08-04T06:22:35.432741Z",
          "start_time": "2025-08-04T06:21:56.386038Z"
        },
        "id": "60cc0688d9180b"
      },
      "cell_type": "code",
      "source": [
        "vector_store = CustomVectorStore(\n",
        "    embedding_model=embedding_model,\n",
        "    documents=documents,\n",
        "    metadata=metadata\n",
        ")"
      ],
      "id": "60cc0688d9180b",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-08-04T06:23:04.785880Z",
          "start_time": "2025-08-04T06:23:04.730037Z"
        },
        "id": "8b8d8b65fb7a55a1"
      },
      "cell_type": "code",
      "source": [
        "vector_store.search(\"Apple earnings\", k=3)  # Test the search method"
      ],
      "id": "8b8d8b65fb7a55a1",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "824cbe153c96f114"
      },
      "cell_type": "markdown",
      "source": [
        "## Using your vector store and analyzing the results\n"
      ],
      "id": "824cbe153c96f114"
    },
    {
      "cell_type": "markdown",
      "id": "d97d64a4",
      "metadata": {
        "id": "d97d64a4"
      },
      "source": [
        "### Retrieve AI Announcements\n",
        "\n",
        " Now that your vector store is working, let's use it to retrieve relevant documents.\n",
        "\n",
        " 👉 **Instructions**:\n",
        " - Perform a semantic search using the query `\"AI announcement\"` with `k=50` to retrieve the top 50 most relevant articles.\n",
        " - Display each result's:\n",
        "   - `TICKER`\n",
        "   - `PUBLICATION_DATE`\n",
        "   - `PROVIDER`\n",
        "   - Similarity score\n",
        "   - Full document text\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def display_search_results(results):\n",
        "    for doc, meta, similarity in results:\n",
        "        print(\"=\"*64)\n",
        "        print(f\"{meta['TICKER']:<6} | {meta['PUBLICATION_DATE']} | {meta['PROVIDER']}\")\n",
        "        print(f\"Similarity: {similarity:.4f}\")\n",
        "        print(\"-\"*64)\n",
        "        print(doc)\n",
        "        print(\"=\"*64)\n",
        "        print(\"\\n\\n\")"
      ],
      "metadata": {
        "id": "LVbxVYxuEcq1"
      },
      "id": "LVbxVYxuEcq1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "id": "ac4822fd",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-08-04T06:20:00.093959600Z",
          "start_time": "2025-07-31T06:08:40.991627Z"
        },
        "id": "ac4822fd"
      },
      "source": [
        "results = vector_store.search(\"AI announcement\", k=50)\n",
        "\n",
        "display_search_results(results)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "728f353e1ebd09f6"
      },
      "cell_type": "markdown",
      "source": [
        " ### **Q1.** What are the top companies (by TICKER) most frequently appearing in the top 50 search results for the query \"AI announcement\"?\n",
        " Check their company names on Yahoo Finance. Are you surprised by the results?\n",
        "\n",
        " ✅ **Your task**:\n",
        " - Count the number of times each TICKER appears.\n",
        " - Print and analyze the top results."
      ],
      "id": "728f353e1ebd09f6"
    },
    {
      "cell_type": "code",
      "id": "0a9e7b76",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-08-04T06:20:00.093959600Z",
          "start_time": "2025-07-31T06:20:34.753238Z"
        },
        "id": "0a9e7b76"
      },
      "source": [
        "count_by_ticker = {}\n",
        "\n",
        "for _, meta, _ in results:\n",
        "    t = meta['TICKER']\n",
        "\n",
        "    if t in count_by_ticker:\n",
        "        count_by_ticker[t] += 1\n",
        "\n",
        "    else:\n",
        "        count_by_ticker[t] = 1\n",
        "\n",
        "sorted_tickers_count = sorted(count_by_ticker.items(), key=lambda x: x[1], reverse=True)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-08-04T06:20:00.093959600Z",
          "start_time": "2025-07-31T06:21:11.348897Z"
        },
        "id": "bcd3df66de3af56a"
      },
      "cell_type": "code",
      "source": [
        "# Focusing analysis on tickers appearing more than once\n",
        "filtered_tickers = [(t, c) for t, c in sorted_tickers_count if c > 1]"
      ],
      "id": "bcd3df66de3af56a",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-08-04T06:20:00.093959600Z",
          "start_time": "2025-07-31T06:28:27.047978Z"
        },
        "id": "148907c10a45edca"
      },
      "cell_type": "code",
      "source": [
        "for t, c in filtered_tickers:\n",
        "    comp_name = yf.Ticker(t).info['longName']\n",
        "    print(f\"{comp_name} [{t}] appeared in {c} articles about 'AI announcement'\")"
      ],
      "id": "148907c10a45edca",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "id": "7dfad379",
      "metadata": {
        "id": "7dfad379"
      },
      "source": [
        "Announcements from chipmakers (Intel, AMD, Qualcomm) are to be expected since they are developing new chips with AI accelerators.\n",
        "\n",
        "Microsoft and Amazon were also expected, since they provide the cloud computing services to execute AI workloads, and both of them are introducing AI heavily on their core products. Meta is a similar story; while they don't provide cloud services, they are integrating AI in all their applications, and they are also heavily invested in the development of LLMs.\n",
        "\n",
        "Palantir is the company with the most appearances, and while I may not be that familiar with the company, I do know that they operate in the military sector, which involves a lot of government contracts as well.\n",
        "\n",
        "Baker Hughes and Expedia may not be the first companies the general population thinks about when talking about AI; however, it makes sense to see them in the list since they are starting to adopt AI technologies.\n",
        "\n",
        "Lastly, Cognizant is a consulting company, and that industry is currently investing very heavily in implementing AI solutions for partners and customers.\n"
      ]
    },
    {
      "metadata": {
        "id": "9078b18d774379c"
      },
      "cell_type": "markdown",
      "source": [
        "### **Q2.** What is the date range of the top 50 results? Are the articles evenly distributed across time?\n",
        "\n",
        " ✅ **Your task**:\n",
        " - Extract the publication dates of the top 50 results.\n",
        " - Plot a histogram to visualize the temporal distribution.\n",
        " - Reflect: Are these mentions clustered in recent months or spread evenly?\n",
        "\n",
        " 🧠 **Follow-up**: What could explain the timing of increased AI announcements?"
      ],
      "id": "9078b18d774379c"
    },
    {
      "cell_type": "code",
      "id": "ce25f68f",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-08-04T06:20:00.093959600Z",
          "start_time": "2025-07-31T06:46:47.998219Z"
        },
        "id": "ce25f68f"
      },
      "source": [
        "count_by_date = {}\n",
        "\n",
        "for _, meta, _ in results:\n",
        "    _date = meta['PUBLICATION_DATE']\n",
        "\n",
        "    if _date in count_by_date:\n",
        "        count_by_date[_date] += 1\n",
        "\n",
        "    else:\n",
        "        count_by_date[_date] = 1"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-08-04T06:20:00.093959600Z",
          "start_time": "2025-07-31T06:46:49.309965Z"
        },
        "id": "1d26217ebbfa46bd"
      },
      "cell_type": "code",
      "source": [
        "print(f\"Date ranges from {min(count_by_date.keys())} to {max(count_by_date.keys())}\")"
      ],
      "id": "1d26217ebbfa46bd",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-08-04T06:20:00.093959600Z",
          "start_time": "2025-07-31T06:46:55.690162Z"
        },
        "id": "7dfe6e1711841ed4"
      },
      "cell_type": "code",
      "source": [
        "plt.bar(count_by_date.keys(), count_by_date.values())\n",
        "plt.xlabel('Publication date')\n",
        "plt.ylabel('Number of articles')\n",
        "plt.show()"
      ],
      "id": "7dfe6e1711841ed4",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "id": "67c301aa",
      "metadata": {
        "id": "67c301aa"
      },
      "source": [
        "Articles about AI announcements are not evenly distributed across time. In fact, they are mostly clustered in the second half of May, 2025."
      ]
    },
    {
      "metadata": {
        "id": "a60765b86c5ff910"
      },
      "cell_type": "markdown",
      "source": [
        "## Implement FAISS vector store\n",
        "\n",
        " We’ll now implement a **FAISS-based vector store**, designed for efficient similarity search at scale.\n",
        "\n",
        " 👉 **Steps**:\n",
        " - Use the same sentence transformer model: all-MiniLM-L6-v2.\n",
        " - Encode your text into embessings\n",
        " - Normalize the vectors.\n",
        "\n",
        " FAISS supports multiple similarity types. For cosine similarity, we must:\n",
        "\n",
        " ✅ Normalize vectors to unit length\n",
        " ✅ Use `IndexFlatIP` (inner product), because:\n",
        " - For normalized vectors, inner product = cosine similarity\n"
      ],
      "id": "a60765b86c5ff910"
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = embedding_model.encode(documents)"
      ],
      "metadata": {
        "id": "7dYux1ZQ3viS"
      },
      "id": "7dYux1ZQ3viS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "faiss.normalize_L2(embeddings)"
      ],
      "metadata": {
        "id": "7hFewCZR4MTS"
      },
      "id": "7hFewCZR4MTS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e5db5f46",
      "metadata": {
        "id": "e5db5f46"
      },
      "outputs": [],
      "source": [
        "embedding_size = embeddings.shape[1]\n",
        "\n",
        "index = faiss.IndexFlatIP(embedding_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5ae4d5d9",
      "metadata": {
        "id": "5ae4d5d9"
      },
      "source": [
        "We’ll now:\n",
        " - Initialize the FAISS index\n",
        " - Add the document embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "11dd4db1",
      "metadata": {
        "id": "11dd4db1"
      },
      "outputs": [],
      "source": [
        "index.add(embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "q = embedding_model.encode([\"AI Announcement\"])\n",
        "faiss.normalize_L2(q)\n",
        "d, i = index.search(q, k=5)"
      ],
      "metadata": {
        "id": "oQM4SfjJ61Ws"
      },
      "id": "oQM4SfjJ61Ws",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "c8e7ead7",
      "metadata": {
        "id": "c8e7ead7"
      },
      "source": [
        "### Create a `FaissVectorStore` class with a `.search()` method.\n",
        "\n",
        " This method:\n",
        " - Encodes and normalizes the query\n",
        " - Optionally applies metadata filters\n",
        " - Returns top `k` results with similarity scores and metadata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "07a018df",
      "metadata": {
        "id": "07a018df"
      },
      "outputs": [],
      "source": [
        "class FaissVectorStore:\n",
        "    def __init__(self,\n",
        "                 embedding_model: SentenceTransformer,\n",
        "                 documents: list[str],\n",
        "                 metadata: list[dict[str, str]],\n",
        "                 index: faiss.IndexFlatIP):\n",
        "        self.embedding_model = embedding_model\n",
        "        self.documents = documents\n",
        "        self.metadata = metadata\n",
        "        self.index = index\n",
        "\n",
        "    def search(self,\n",
        "               query: str,\n",
        "               k: int = 5,\n",
        "               metadata_filter: dict[str, str] = None):\n",
        "\n",
        "        query_embedding = self.embedding_model.encode([query])\n",
        "        faiss.normalize_L2(query_embedding)\n",
        "\n",
        "        if metadata_filter is None:\n",
        "            distances, indexes = self.index.search(query_embedding, k)\n",
        "            return self._to_search_result(distances, indexes)\n",
        "\n",
        "        else:\n",
        "            # First create a SearchParameters object that excludes any document\n",
        "            # that doesn't match the metadata.\n",
        "            search_ids = self._filter_documents_id(metadata_filter)\n",
        "            idx_id_selector = faiss.IDSelectorBatch(search_ids)\n",
        "            idx_search_params = faiss.SearchParameters(sel=idx_id_selector)\n",
        "\n",
        "            distances, indexes = self.index.search(\n",
        "                query_embedding, k, params=idx_search_params)\n",
        "\n",
        "            return self._to_search_result(distances, indexes)\n",
        "\n",
        "    def _to_search_result(self, distances, indexes):\n",
        "        r = []\n",
        "\n",
        "        # distances and indexes are of shape (n_queries, n_results)\n",
        "        # Because this class only supports one query at a time,\n",
        "        # we can safely get the first row of the arrays\n",
        "        for d, i in zip(distances[0], indexes[0]):\n",
        "            r.append((self.documents[i], self.metadata[i], d))\n",
        "        return r\n",
        "\n",
        "    def _filter_documents_id(self, metadata_filter):\n",
        "        indexes = []\n",
        "        for i in range(len(self.metadata)):\n",
        "            if self._is_metadata_match(self.metadata[i], metadata_filter):\n",
        "                indexes.append(i)\n",
        "        return indexes\n",
        "\n",
        "    @staticmethod\n",
        "    def _is_metadata_match(document_metadata, metadata_filter):\n",
        "        for key, value in metadata_filter.items():\n",
        "            if key not in document_metadata or document_metadata[key] != value:\n",
        "                return False\n",
        "        return True"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "61bc2c95",
      "metadata": {
        "id": "61bc2c95"
      },
      "source": [
        " Let’s run a semantic search using FAISS:\n",
        " - Query: `\"AI announcement\"`\n",
        " - Top results: `k=50`\n",
        "\n",
        " Print out:\n",
        " - Ticker\n",
        " - Publication date\n",
        " - Provider\n",
        " - Cosine similarity score\n",
        " - Full text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f4ec6157",
      "metadata": {
        "id": "f4ec6157"
      },
      "outputs": [],
      "source": [
        "faiss_vector_store = FaissVectorStore(\n",
        "    embedding_model=embedding_model,\n",
        "    documents=documents,\n",
        "    metadata=metadata,\n",
        "    index=index\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "faiss_results = faiss_vector_store.search(\"AI announcement\", k=50)\n",
        "display_search_results(faiss_results)"
      ],
      "metadata": {
        "id": "hzLViYQxDgch"
      },
      "id": "hzLViYQxDgch",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "b220a146",
      "metadata": {
        "id": "b220a146"
      },
      "source": [
        "## Evaluation: Comparing FAISS Vector Store with your Custom Vector Store"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "22ef9f12",
      "metadata": {
        "id": "22ef9f12"
      },
      "source": [
        "### Retrieval Comparison Across Systems\n",
        "\n",
        " 👉 **Instructions**:\n",
        "\n",
        " - Using the 5 'test_queries' provided in the list below, retrieve the top 5 news for each query using both your custom and FAISS vector stores.\n",
        " - Inspect how similar the returned news texts are for each query.\n",
        " - Focus especially on the order of results (not just their presence).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2a2c9487",
      "metadata": {
        "id": "2a2c9487"
      },
      "outputs": [],
      "source": [
        "test_queries = [\n",
        "    'Stock price drop',\n",
        "    'Layoffs',\n",
        "    'Mergers and acquisitions',\n",
        "    'Fed interest rate',\n",
        "    'Regulation',\n",
        "    'Cryptocurrency'\n",
        "\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compare_search_results(a, b, labels=['Results 1', 'Results 2']):\n",
        "    for a_i, b_i in zip(a,b):\n",
        "        doc_a, meta_a, similarity_a = a_i\n",
        "        doc_b, meta_b, similarity_b = b_i\n",
        "\n",
        "        lines = max(len(doc_a), len(doc_b))//60 + 1\n",
        "\n",
        "        print(f\"{labels[0]:=^64}\\t{labels[1]:=^64}\")\n",
        "\n",
        "        a_meta = f\"{meta_a['TICKER']:<6} | {meta_a['PUBLICATION_DATE']} | {meta_a['PROVIDER']}\"\n",
        "        b_meta = f\"{meta_b['TICKER']:<6} | {meta_b['PUBLICATION_DATE']} | {meta_b['PROVIDER']}\"\n",
        "        print(f\"{a_meta:<64}\\t{b_meta}\")\n",
        "\n",
        "        print(f\"{f'Similarity: {similarity_a:.4f}':<64}\\t{f'Similarity: {similarity_b:.4f}':<64}\")\n",
        "\n",
        "        print(f\"{'-'*64}\\t{'-'*64}\")\n",
        "        for i in range(lines):\n",
        "            print(f\"{doc_a[i*60:(i+1)*60]:<64}\\t{doc_b[i*60:(i+1)*60]:<64}\")\n",
        "\n",
        "        print(f\"{'='*64}\\t{'='*64}\")\n",
        "        print(\"\\n\\n\")"
      ],
      "metadata": {
        "id": "VxXSniPcFAVs"
      },
      "id": "VxXSniPcFAVs",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2468922e",
      "metadata": {
        "id": "2468922e"
      },
      "outputs": [],
      "source": [
        "for tq in test_queries:\n",
        "    print(f\"Query: '{tq}'\")\n",
        "\n",
        "    custom_result = vector_store.search(tq, k=5)\n",
        "    faiss_result = faiss_vector_store.search(tq, k=5)\n",
        "\n",
        "    compare_search_results(custom_result, faiss_result, labels=['Custom Vector Store', 'FAISS'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bb35bc09",
      "metadata": {
        "id": "bb35bc09"
      },
      "source": [
        "### **Q3.** Do you observe any significant differences in the top-5 retrieved results for each query between the two systems? Explain why these differences may or may not occur."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3fcda4c1",
      "metadata": {
        "id": "3fcda4c1"
      },
      "source": [
        "The results are always the same, in terms of the documents returned, their similarity score and ranking. This is because we are using the exact same embedding model and the same similarity measure (cosine similarity). If we were to change any of these parameters (for example, by using a diferent type of faiss index), we might get different results."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ae334b87",
      "metadata": {
        "id": "ae334b87"
      },
      "source": [
        "## Evaluation: Comparing 2 embedding models with your Custom Vector Store\n",
        "\n",
        " 👉 **Instructions**:\n",
        "\n",
        " - Implement your custom vector store with `'all-MiniLM-L6-v2'` model from `sentence-transformers`, and compare it with the `'all-mpnet-base-v2'` model from `sentence-transformers`.\n",
        " - Similarly, retrieve the top 5 news for each query using both implementations.\n",
        " - Inspect how similar the returned news texts are for each query.\n",
        " - Focus especially on the order of results (not just their presence)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "edd2d656",
      "metadata": {
        "id": "edd2d656"
      },
      "outputs": [],
      "source": [
        "all_minilm_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "all_mpnet_model = SentenceTransformer('all-mpnet-base-v2')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mini_lm_vector_store = CustomVectorStore(\n",
        "    embedding_model=all_minilm_model,\n",
        "    documents=documents,\n",
        "    metadata=metadata)"
      ],
      "metadata": {
        "id": "C1UwO3bHLrUh"
      },
      "id": "C1UwO3bHLrUh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mpnet_vector_store = CustomVectorStore(\n",
        "    embedding_model=all_mpnet_model,\n",
        "    documents=documents,\n",
        "    metadata=metadata)"
      ],
      "metadata": {
        "id": "o4r6opa6LzVU"
      },
      "id": "o4r6opa6LzVU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for tq in test_queries:\n",
        "    print(f\"Query: '{tq}'\")\n",
        "\n",
        "    a_result = mini_lm_vector_store.search(tq, k=5)\n",
        "    b_result = mpnet_vector_store.search(tq, k=5)"
      ],
      "metadata": {
        "id": "lVW0dWW2L3Jn"
      },
      "id": "lVW0dWW2L3Jn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "a7cf2d8b",
      "metadata": {
        "id": "a7cf2d8b"
      },
      "source": [
        "### **Q4.**  Which embedding model performs better in retrieving relevant documents for the queries? Support your answer with specific examples from the results."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8fe6a06a",
      "metadata": {
        "id": "8fe6a06a"
      },
      "source": [
        " YOUR WRITTEN RESPONSE HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b97a59c2",
      "metadata": {
        "id": "b97a59c2"
      },
      "source": [
        "## 🛠️ Implementation-Level Questions"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5a0bb91d",
      "metadata": {
        "id": "5a0bb91d"
      },
      "source": [
        "### **Q5.**  What role does vector normalization play in each implementation?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9e2ae5ce",
      "metadata": {
        "id": "9e2ae5ce"
      },
      "source": [
        "\n",
        " YOUR WRITTEN RESPONSE HERE\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c8d99e5d",
      "metadata": {
        "id": "c8d99e5d"
      },
      "source": [
        "\n",
        "### **Q6.**  What would happen if vectors were not normalized before indexing?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f3555035",
      "metadata": {
        "id": "f3555035"
      },
      "source": [
        "\n",
        " YOUR WRITTEN RESPONSE HERE\n",
        "\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "219a98d4",
      "metadata": {
        "id": "219a98d4"
      },
      "source": [
        "\n",
        "## 🧠 Critical Thinking / Design Choices"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d1f51461",
      "metadata": {
        "id": "d1f51461"
      },
      "source": [
        "\n",
        "### **Q7.** Which implementation would you choose for a production-scale search system? Why?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e016271a",
      "metadata": {
        "id": "e016271a"
      },
      "source": [
        "\n",
        " YOUR WRITTEN RESPONSE HERE\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b0354130",
      "metadata": {
        "id": "b0354130"
      },
      "source": [
        "\n",
        "### **Q8.**   If your dataset grows from 5K to 5M articles, which implementation will scale better? Justify your answer."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f1eafffa",
      "metadata": {
        "id": "f1eafffa"
      },
      "source": [
        "\n",
        " YOUR WRITTEN RESPONSE HERE\n",
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}